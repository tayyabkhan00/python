Regularization :

Regularization is a technique used to stop a model from memorizing data and instead help it learn properly.
üëâ Think of it like this:
A good student understands concepts
A bad student memorizes answers
Regularization makes the model a good student üëç
It adds rules or limits so the model does not become too complex.

What is Overfitting?
Overfitting happens when a model:
Learns the training data too well
But fails on new (unseen) data
üìå The model remembers noise and small details that are not actually important.

Real-Life Example
Imagine preparing for an exam:
You memorize past question papers ‚Üí you score high on practice tests
In the real exam, questions change ‚Üí you fail
üëâ This is overfitting.

In Machine Learning Terms
Training accuracy ‚Üí very high
Testing accuracy ‚Üí low
This means the model has overfitted.

Why Overfitting is Bad
Model does not generalize
Performs poorly in real-world use
Gives false confidence

How Regularization Fixes Overfitting
Regularization controls the model‚Äôs freedom.
Common regularization methods (simple idea):
L1 / L2 Regularization ‚Üí stop weights from becoming too large or
L1 regularization ‚Üí makes weights sparse
L2 regularization ‚Üí reduces weight magnitude
Dropout ‚Üí randomly turn off neurons so model can‚Äôt depend on only a few
Early Stopping ‚Üí stop training before memorization starts
Data Augmentation ‚Üí show more varied data or increase dataset size

One-Line Exam Definitions
Overfitting: When a model performs well on training data but poorly on new data.
Regularization: Techniques used to reduce overfitting by controlling model complexity.

Batch-normalization:
Batch Normalization is a technique used to normalize layer activations for each mini-batch to reduce internal 
covariate shift. It normalizes the mean and variance of activations and then applies learnable scale and shift parameters. 
Batch Normalization improves training speed, stabilizes gradients, allows higher learning rates, and also acts as a 
regularizer.
or we can say that, Batch Normalization is a technique used in deep neural networks to normalize the activations of a
layer for each mini-batch, so that they have zero mean and unit variance, followed by learnable scaling and shifting.
üëâ Introduced by Ioffe and Szegedy (2015).

Why Batch Normalization is Needed
Deep networks suffer from:
(a) Internal Covariate Shift
Distribution of activations changes as network parameters update.
Slows training and causes instability.
(b) Problems Without BatchNorm
Slow convergence
Vanishing/exploding gradients
High sensitivity to learning rate
Overfitting
BatchNorm stabilizes training.

Placement of Batch Normalization in a Network
Correct Placement (Most Common)
Linear / Conv ‚Üí BatchNorm ‚Üí Activation (ReLU)

Why before activation?
Keeps normalized distribution before non-linearity
Improves gradient flow

Batch Normalization During Training vs Testing
During Training
  Mean and variance computed from mini-batch
  Running averages are maintained
During Testing (Inference)
  Use running mean and running variance
  No batch dependency ‚Üí stable predictions

Backpropagation in Batch Normalization
1.Gradients flow through:
 -normalization step
 -scaling (Œ≥)
 -shifting (Œ≤)
2.Œ≥ and Œ≤ are trained using gradient descent.
3.BatchNorm reduces vanishing gradient problem.
(üëâ You don‚Äôt need full derivation unless explicitly asked.)

Advantages of Batch Normalization
(Highly Important for Exams)
‚úÖ Faster convergence
‚úÖ Allows higher learning rates
‚úÖ Reduces vanishing/exploding gradients
‚úÖ Acts as regularizer
‚úÖ Less sensitive to initialization
‚úÖ Improves generalization

Disadvantages / Limitations
‚ùå Depends on batch size
‚ùå Performs poorly with very small batches
‚ùå Extra computation
‚ùå Less effective in RNNs (LayerNorm preferred)

Batch Normalization vs Other Normalization Techniques:
| Technique    | Normalization Scope | Used In            |
| ------------ | ------------------- | ------------------ |
| BatchNorm    | Across batch        | CNNs, DNNs         |
| LayerNorm    | Across features     | Transformers, RNNs |
| InstanceNorm | Per sample          | Style transfer     |
| GroupNorm    | Groups of channels  | Small batch CNNs   |

Batch Normalization in CNNs:
1.Applied per feature map
2.Mean and variance computed over:
 -batch size
 -spatial dimensions
This preserves spatial structure.

One-Line Exam Facts:
Introduced in 2015
Parameters: Œ≥ and Œ≤
Reduces internal covariate shift
Often removes need for dropout
Used heavily in CNNs

VC Dimension and Neural Nets (Exam Definition)
VC Dimension = a measure of model capacity (how many patterns it can "shatter").
Key points
Higher VC dimension ‚Üí more complex model
Deep networks have very high VC dimension
High VC ‚Üí more risk of overfitting unless properly regularized