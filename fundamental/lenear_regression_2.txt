**â­ If outcome is a number, linear regression is used.**

ğŸ“ The Math (very simple)
Linear regression equation:
y = m Ã— x + b
m = slope (how steep the line is)
b = intercept (where line starts)
x = input
y = predicted value
But donâ€™t worry â€” sklearn calculates m and b automatically.

â­ Key Terms (explained very easy):
Training â†’ feeding data to learn the best line
Model â†’ the line created
Prediction â†’ using the line to guess new values
Loss/Error â†’ how far prediction is from real value
RÂ² score â†’ how good the line is (0 to 1)

ğŸ¯ Cost Function (Mean Squared Error):
This measures how bad the line is.
MSE = average of (predicted â€“ actual)Â²
Why squared?
Because negative errors should not cancel positive ones.
Goal: Make error as small as possible.

ğŸ¯ Gradient Descent (How the model learns m and b):
Think of a ball rolling down a hill.
Ball = algorithm
Hill = error
Bottom = best values of m & b
Gradient descent updates:
m = m â€“ learning_rate Ã— derivative
b = b â€“ learning_rate Ã— derivative
This slowly finds the optimal slope & intercept.
â¡ï¸ You donâ€™t manually do this.
sklearn does it for you.

ğŸ¯ â­ Final Summary:
Linear Regression is:
âœ” simplest ML model
âœ” used to predict numbers
âœ” finds best straight line
âœ” uses MSE + Gradient Descent
âœ” easy to implement and interpret
âœ” perfect first ML algorithm