<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>3D Particle System — Control with Hand (MediaPipe + three.js)</title>
  <style>
    html,body{height:100%;margin:0;background:#050505;color:#ddd;overflow:hidden}
    #ui{position:absolute;left:12px;top:12px;z-index:20;font-family:sans-serif}
    #ui small{opacity:.8}
    #videoCanvas{position: absolute; right: 12px; bottom: 12px; width:200px; border-radius:8px; box-shadow:0 6px 18px rgba(0,0,0,.6); transform: scaleX(-1);} /* mirrored */
    /* Make the canvas for three.js fill the screen */
    canvas.three{display:block}
  </style>
</head>
<body>
  <div id="ui">
    <h3>3D Hand‑Controlled Particles</h3>
    <div><small>Move your hand inside the webcam view to influence particles. Pinch (thumb+index) to toggle repulsion.</small></div>
    <div style="margin-top:8px"><small>Allow camera when prompted.</small></div>
  </div>

  <!-- small mirrored video preview for feedback (MediaPipe will draw into this) -->
  <canvas id="videoCanvas" width="640" height="480"></canvas>

  <!-- three.js and MediaPipe libs from CDNs -->
  <script src="https://unpkg.com/three@0.153.0/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <script>
  // ---------- Configuration ----------
  const PARTICLE_COUNT = 22000; // tweak: more particles -> slower
  const AREA = 30; // spread of the particle field
  const HAND_FORCE = 120; // strength multiplier
  const HAND_RADIUS = 6.0; // how far the hand affects particles
  const DAMPING = 0.96; // velocity damping per frame

  // ---------- three.js scene setup ----------
  const scene = new THREE.Scene();
  scene.fog = new THREE.FogExp2(0x050505, 0.02);

  const camera = new THREE.PerspectiveCamera(60, innerWidth/innerHeight, 0.1, 1000);
  camera.position.set(0, 6, 40);

  const renderer = new THREE.WebGLRenderer({antialias:true});
  renderer.setPixelRatio(window.devicePixelRatio);
  renderer.setSize(innerWidth, innerHeight);
  renderer.domElement.classList.add('three');
  document.body.appendChild(renderer.domElement);

  window.addEventListener('resize', ()=>{
    camera.aspect = innerWidth/innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(innerWidth, innerHeight);
  });

  // simple soft light
  const dir = new THREE.DirectionalLight(0xffffff, 0.6);
  dir.position.set(1,1,1);
  scene.add(dir);
  scene.add(new THREE.AmbientLight(0x707070, 0.8));

  // ---------- Particles ----------
  const geometry = new THREE.BufferGeometry();
  const positions = new Float32Array(PARTICLE_COUNT * 3);
  const velocities = new Float32Array(PARTICLE_COUNT * 3); // for x,y,z velocities

  // initialize positions and small random velocities
  for (let i=0;i<PARTICLE_COUNT;i++){
    const idx = i*3;
    positions[idx] = (Math.random()-0.5) * AREA;
    positions[idx+1] = (Math.random()-0.5) * AREA * 0.6;
    positions[idx+2] = (Math.random()-0.5) * AREA;
    velocities[idx] = (Math.random()-0.5) * 0.02;
    velocities[idx+1] = (Math.random()-0.5) * 0.02;
    velocities[idx+2] = (Math.random()-0.5) * 0.02;
  }
  geometry.setAttribute('position', new THREE.BufferAttribute(positions,3).setUsage(THREE.DynamicDrawUsage));

  const material = new THREE.PointsMaterial({
    size:0.12,
    sizeAttenuation:true,
    color:0x66ccff,
    transparent:true,
    opacity:0.9,
    depthWrite:false,
    blending:THREE.AdditiveBlending
  });

  const points = new THREE.Points(geometry, material);
  scene.add(points);

  // ---------- Helpers for transforming normalized webcam coords -> world ----------
  const tmpVec = new THREE.Vector3();
  function webcamToWorld(nx, ny, depth=0.0){
    // nx,ny are normalized [0,1] from MediaPipe (origin top-left). We mirror camera horizontally so flip x.
    const ndcX = (1 - nx) * 2 - 1; // mirror
    const ndcY = - (ny * 2 - 1);
    // set z in ndc space; 0 means near plane, 1 far plane; pick 0.5 then unproject
    tmpVec.set(ndcX, ndcY, depth*2 - 1);
    tmpVec.unproject(camera);
    return tmpVec.clone();
  }

  // ---------- MediaPipe Hands setup ----------
  const videoCanvas = document.getElementById('videoCanvas');
  const vctx = videoCanvas.getContext('2d');

  let currentHand = null; // object {pos:Vector3, pinch:bool}

  const hands = new Hands({locateFile: (file) => {
    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
  }});
  hands.setOptions({
    maxNumHands: 1,
    modelComplexity: 1,
    minDetectionConfidence: 0.6,
    minTrackingConfidence: 0.6
  });

  hands.onResults(results=>{
    vctx.save();
    vctx.clearRect(0,0,videoCanvas.width, videoCanvas.height);
    // draw mirrored
    vctx.translate(videoCanvas.width, 0);
    vctx.scale(-1,1);
    if (results.image) vctx.drawImage(results.image, 0, 0, videoCanvas.width, videoCanvas.height);
    // draw landmarks small circles
    if (results.multiHandLandmarks && results.multiHandLandmarks.length>0){
      const landmarks = results.multiHandLandmarks[0];
      // use landmark 8 (index_finger_tip) for position and distance to thumb tip (4) for pinch
      const ix = landmarks[8].x; const iy = landmarks[8].y;
      const tx = landmarks[4].x; const ty = landmarks[4].y;
      const pinchDist = Math.hypot(ix-tx, iy-ty);
      // draw landmarks for feedback
      vctx.fillStyle='rgba(0,0,0,0.5)';
      for (let p of landmarks){
        vctx.beginPath(); vctx.arc(p.x*videoCanvas.width, p.y*videoCanvas.height, 6,0,Math.PI*2); vctx.fill();
      }
      // convert to world
      const world = webcamToWorld(ix, iy, 0.5);
      currentHand = {pos: world, pinch: pinchDist < 0.05};

      // draw a small circle where processed (mirrored) index finger is
      vctx.fillStyle = currentHand.pinch ? 'rgba(255,80,80,0.9)' : 'rgba(80,255,160,0.9)';
      vctx.beginPath();
      vctx.arc(ix*videoCanvas.width, iy*videoCanvas.height, currentHand.pinch?14:10, 0, Math.PI*2);
      vctx.fill();
    } else {
      currentHand = null;
    }
    vctx.restore();
  });

  // camera setup using MediaPipe camera utils
  const videoElement = document.createElement('video');
  videoElement.style.display='none';
  videoElement.playsInline = true;
  document.body.appendChild(videoElement);

  const cameraFeed = new Camera(videoElement,{
    onFrame: async ()=>{ await hands.send({image: videoElement}); },
    width: 640, height: 480
  });
  cameraFeed.start();

  // ---------- Animation loop: apply forces from hand to particles ----------
  const posAttr = geometry.getAttribute('position');

  function animate(){
    requestAnimationFrame(animate);

    const now = performance.now();

    // update particles
    if (currentHand){
      const hx = currentHand.pos.x, hy = currentHand.pos.y, hz = currentHand.pos.z;
      const isPinched = currentHand.pinch; // if true -> repulsion, else attraction

      for (let i=0;i<PARTICLE_COUNT;i++){
        const idx = i*3;
        let px = posAttr.array[idx], py = posAttr.array[idx+1], pz = posAttr.array[idx+2];

        // vector from particle -> hand
        let dx = hx - px, dy = hy - py, dz = hz - pz;
        const distSq = dx*dx + dy*dy + dz*dz + 0.0001;
        const dist = Math.sqrt(distSq);
        if (dist < HAND_RADIUS){
          // normalized direction
          dx /= dist; dy /= dist; dz /= dist;
          // inverse-square-ish force scaled by HAND_FORCE and falloff
          const strength = (1 - (dist / HAND_RADIUS)) * (HAND_FORCE / (distSq));
          // if pinched -> push away, else pull in
          const sign = isPinched ? -1 : 1;
          velocities[idx] += dx * strength * sign;
          velocities[idx+1] += dy * strength * sign;
          velocities[idx+2] += dz * strength * sign;
        }

        // apply velocity to position
        posAttr.array[idx] += velocities[idx];
        posAttr.array[idx+1] += velocities[idx+1];
        posAttr.array[idx+2] += velocities[idx+2];

        // damping
        velocities[idx] *= DAMPING;
        velocities[idx+1] *= DAMPING;
        velocities[idx+2] *= DAMPING;

        // keep within bounds softly: if too far, pull back slowly
        const bound = AREA*0.9;
        if (posAttr.array[idx] > bound) posAttr.array[idx] = -bound;
        if (posAttr.array[idx] < -bound) posAttr.array[idx] = bound;
        if (posAttr.array[idx+1] > bound) posAttr.array[idx+1] = -bound;
        if (posAttr.array[idx+1] < -bound) posAttr.array[idx+1] = bound;
        if (posAttr.array[idx+2] > bound) posAttr.array[idx+2] = -bound;
        if (posAttr.array[idx+2] < -bound) posAttr.array[idx+2] = bound;
      }
    } else {
      // slight float when no hand
      for (let i=0;i<PARTICLE_COUNT;i++){
        const idx=i*3;
        posAttr.array[idx] += velocities[idx];
        posAttr.array[idx+1] += velocities[idx+1];
        posAttr.array[idx+2] += velocities[idx+2];
        velocities[idx] *= DAMPING; velocities[idx+1] *= DAMPING; velocities[idx+2] *= DAMPING;
      }
    }

    posAttr.needsUpdate = true;

    // simple camera slow orbit for nicer view
    const t = performance.now()*0.00005;
    camera.position.x = Math.sin(t)*40;
    camera.position.z = Math.cos(t)*40;
    camera.lookAt(0,0,0);

    renderer.render(scene, camera);
  }

  animate();

  // ---------- small user instructions for permission ----------
  // Note: MediaPipe's Camera helper automatically asks for permission when start() is called

  </script>
</body>
</html>
